{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    number_of_hours = 12\n",
    "    number_of_patients = int(data.shape[0]/number_of_hours)\n",
    "    statistical_features = int(data.shape[1])-3  # Number of columns - pid - age - time\n",
    "\n",
    "    # Transforming train features into an array where each element is one patient\n",
    "    train_features_array = np.array(data)\n",
    "    patients = np.vsplit(train_features_array , number_of_patients)\n",
    "    patients_array = np.array(patients)\n",
    "    \n",
    "    # We are creating a new matrix (Phi) that contains statistical features for every patient: pid, age, features: mean, var, max, min, median\n",
    "    features = np.zeros([number_of_patients, 2+5*statistical_features]) # no. of patients, no. of features* no. of columns names(age, calcium, bolirubin...)\n",
    "    # columns are: pid, age, mean(of all featuers), var, max, min, median\n",
    "    \n",
    "    features[:,0] = patients_array[:,0,0] # 1st column is Patient id\n",
    "    features[:,1] = patients_array[:,0,2] # 2nd column is Age\n",
    "    \n",
    "    means = np.nanmean(patients_array[:, :, 3:], axis=1) # rest of the columns are means, var... of all values\n",
    "    features[:,2:statistical_features+2] = means\n",
    "    \n",
    "    variances = np.nanvar(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,statistical_features+2:2*statistical_features+2] = variances\n",
    "    \n",
    "    maxs = np.nanmax(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,2*statistical_features+2:3*statistical_features+2] = maxs\n",
    "    \n",
    "    mins = np.nanmin(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,3*statistical_features+2:4*statistical_features+2] = mins\n",
    "    \n",
    "    medians = np.nanmedian(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,4*statistical_features+2:5*statistical_features+2] = medians\n",
    "    \n",
    "    # Replacing the NaN values with the mean of all patients\n",
    "    all_means = np.nanmean(features, axis=0)  # Calculate the mean of each features of all patients\n",
    "    \n",
    "    # find indexes where NaNs are and replace them by the column mean\n",
    "    indexes = np.where(np.isnan(features))\n",
    "    features[indexes] = np.take(all_means, indexes[1])\n",
    "    \n",
    "    # imp = SimpleImputer(missing_values=np.nan, strategy='mean') # I put imputer here just because they mentioned it in the task description\n",
    "    # features = imp.fit_transform(features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the files\n",
    "train_features = pd.read_csv(\"train_features.csv\") # training X\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")     # training Y\n",
    "test_features = pd.read_csv(\"test_features.csv\")   # testing X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b30608da73c9>:18: RuntimeWarning: Mean of empty slice\n",
      "  means = np.nanmean(patients_array[:, :, 3:], axis=1) # rest of the columns are means, var... of all values\n",
      "<ipython-input-2-b30608da73c9>:21: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  variances = np.nanvar(patients_array[:, :, 3:], axis=1);\n",
      "<ipython-input-2-b30608da73c9>:24: RuntimeWarning: All-NaN slice encountered\n",
      "  maxs = np.nanmax(patients_array[:, :, 3:], axis=1);\n",
      "<ipython-input-2-b30608da73c9>:27: RuntimeWarning: All-NaN slice encountered\n",
      "  mins = np.nanmin(patients_array[:, :, 3:], axis=1);\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing both train and test features: creating an array of patients, creating statistical features (mean, var, max..)\n",
    "# for all features for each patient, getting rid of NaN values with filling them with means.\n",
    "train_X = preprocess(train_features)\n",
    "test_X = preprocess(test_features)\n",
    "\n",
    "#Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "train_X[:,2:] = scaler.fit_transform(train_X[:,2:])  # Skipping pid and age\n",
    "\n",
    "test_X[:,2:] = scaler.fit_transform(test_X[:,2:])\n",
    "\n",
    "# Exporting train_X into csv file for better observing\n",
    "df = pd.DataFrame(train_X)\n",
    "df.to_csv('train_X2.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ignore these warnings. It reports that somewhere in calculating mean/var.. of all values we get NaN for columns that contist only of NaN's. Afterwards we were dealing with these NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts 1 & 2 (They're basically the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data we need for subtasks 1 & 2\n",
    "train_Y = np.array(train_labels.loc[: , \"pid\":\"LABEL_Sepsis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "no_columns = 12\n",
    "predictions_part_1_2 = np.zeros([test_X.shape[0], no_columns])\n",
    "\n",
    "for i in range(1, no_columns) :  # We are fitting columns (medical tests) one by one\n",
    "    \n",
    "    model.fit(train_X, train_Y[:, i])\n",
    "    output_proba = model.predict_proba(test_X) \n",
    "    predictions_part_1_2[:, i] = output_proba[:,1]\n",
    "    \n",
    "    # ROC for analyzing\n",
    "    print(roc_auc_score(train_Y[:, i], model.predict_proba(train_X)[:, 1])) # This gives all ones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.05],\n",
       "       [0.97, 0.03],\n",
       "       [0.95, 0.05],\n",
       "       ...,\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [0.98, 0.02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 1.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+01, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+02, 1.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [9.996e+03, 1.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [9.998e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [9.999e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_part_1_2[:, 0] = test_X[:, 0].astype(int) # 1st columns is just pid-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 8.2000e-01, 5.2000e-01, ..., 2.5000e-01, 5.0000e-02,\n",
       "        1.9000e-01],\n",
       "       [1.0001e+04, 2.0000e-02, 2.0000e-02, ..., 1.0000e-02, 4.0000e-02,\n",
       "        1.0000e-02],\n",
       "       [1.0003e+04, 6.0000e-02, 2.0000e-02, ..., 2.0000e-02, 2.0000e-02,\n",
       "        2.0000e-02],\n",
       "       ...,\n",
       "       [9.9920e+03, 5.7000e-01, 5.0000e-02, ..., 2.0000e-02, 0.0000e+00,\n",
       "        8.0000e-02],\n",
       "       [9.9940e+03, 6.8000e-01, 4.7000e-01, ..., 3.0000e-01, 2.0000e-01,\n",
       "        3.6000e-01],\n",
       "       [9.9970e+03, 8.2000e-01, 3.0000e-02, ..., 6.0000e-02, 1.0000e-02,\n",
       "        3.0000e-02]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_part_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data we need for subtask 3\n",
    "train_Y = np.array(train_labels.loc[: , \"LABEL_RRate\":\"LABEL_Heartrate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor = SGDRegressor(max_iter = 1000)\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_columns = 4\n",
    "predictions_part_3 = np.zeros([test_X.shape[0], no_columns])\n",
    "for i in range(no_columns) :\n",
    "    regressor.fit(train_X, train_Y[:, i])\n",
    "    output = regressor.predict(test_X)\n",
    "    predictions_part_3[:, i] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.concatenate((predictions_part_1_2,predictions_part_3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output, columns = ['pid','LABEL_BaseExcess','LABEL_Fibrinogen','LABEL_AST','LABEL_Alkalinephos','LABEL_Bilirubin_total','LABEL_Lactate','LABEL_TroponinI','LABEL_SaO2','LABEL_Bilirubin_direct','LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate','LABEL_ABPm','LABEL_SpO2','LABEL_Heartrate'])\n",
    "\n",
    "df.to_csv('prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 8.2000e-01, 5.2000e-01, ..., 2.5000e-01, 5.0000e-02,\n",
       "        1.9000e-01],\n",
       "       [1.0001e+04, 2.0000e-02, 2.0000e-02, ..., 1.0000e-02, 4.0000e-02,\n",
       "        1.0000e-02],\n",
       "       [1.0003e+04, 6.0000e-02, 2.0000e-02, ..., 2.0000e-02, 2.0000e-02,\n",
       "        2.0000e-02],\n",
       "       ...,\n",
       "       [9.9920e+03, 5.7000e-01, 5.0000e-02, ..., 2.0000e-02, 0.0000e+00,\n",
       "        8.0000e-02],\n",
       "       [9.9940e+03, 6.8000e-01, 4.7000e-01, ..., 3.0000e-01, 2.0000e-01,\n",
       "        3.6000e-01],\n",
       "       [9.9970e+03, 8.2000e-01, 3.0000e-02, ..., 6.0000e-02, 1.0000e-02,\n",
       "        3.0000e-02]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_part_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
