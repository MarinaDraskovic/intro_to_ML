{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import roc_curve as rocc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict as CVP\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the files\n",
    "train_features = pd.read_csv(\"train_features.csv\") # training X\n",
    "train_labels = pd.read_csv(\"train_labels.csv\") # training Y\n",
    "test_features = pd.read_csv(\"test_features.csv\") # testing X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    # Transforming train features into an array where each element is one patient\n",
    "    featureaary = np.array(data)\n",
    "    number_of_hours = 12\n",
    "    patients = np.vsplit(featureaary , int(data.shape[0]/number_of_hours))\n",
    "    patients_array = np.array(patients)\n",
    "    \n",
    "    # We are creating a new matrix (Phi) that contains statistical features for every patient: pid, age, mean, var, max, min,median\n",
    "    features = np.zeros([int(data.shape[0]/number_of_hours), 2+5*34]) # no of patients, no of features* no of columns names(age, calcium, bolirubin...)\n",
    "    # columns are: pid, age, mean(of all featuers), var, max, min, median\n",
    "    \n",
    "    features[:,0] = patients_array[:,0,0] #Patient id\n",
    "    features[:,1] = patients_array[:,0,2] # Age\n",
    "\n",
    "    means = np.nanmean(patients_array[:, :, 3:], axis=1)\n",
    "    statistical_features = int(data.shape[1])-3  # Number of columns - pid - age - time\n",
    "    \n",
    "    features[:,2:statistical_features+2] = means\n",
    "    \n",
    "    variances = np.nanvar(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,statistical_features+2:2*statistical_features+2] = variances\n",
    "    \n",
    "    maxs = np.nanmax(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,2*statistical_features+2:3*statistical_features+2] = maxs\n",
    "    \n",
    "    mins = np.nanmin(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,3*statistical_features+2:4*statistical_features+2] = mins\n",
    "    \n",
    "    medians = np.nanmedian(patients_array[:, :, 3:], axis=1);\n",
    "    features[:,4*statistical_features+2:5*statistical_features+2] = medians\n",
    "    \n",
    "    #Replacing the NaN values with the mean of all patients\n",
    "    # Calculate the mean of each features of all patients\n",
    "    all_means = np.nanmean(features, axis=0)\n",
    "    \n",
    "    # find indexes where NaNs are and replace them by the column mean\n",
    "    indexes = np.where(np.isnan(features))\n",
    "    features[indexes] = np.take(all_means, indexes[1])\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: All-NaN slice encountered\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: All-NaN slice encountered\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3250: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_X = preprocess(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ignore these warnings as the result still make sense. We get NaN for columns that contist only of NaN's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we have a nice $\\Phi$ matrix, we need to take care of the remaining NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: Mean of empty slice\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: All-NaN slice encountered\n",
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: All-NaN slice encountered\n"
     ]
    }
   ],
   "source": [
    "test_X = preprocess(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, we finally have usable features to train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 & 2 (They're basically the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data we need for subtask 1 & 2\n",
    "train_Y = np.array(train_labels.loc[: , \"pid\":\"LABEL_Sepsis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulm\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "predictions_part_1 = np.zeros([12664,12])\n",
    "for i in range(1, 12) :\n",
    "    model.fit(train_X, train_Y[:, i])\n",
    "    output_proba = model.predict_proba(test_X)\n",
    "    predictions_part_1[:, i] = output_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 6.0000e-01, 7.0000e-01, ..., 1.0000e-01, 6.0000e-01,\n",
       "        1.0000e-01],\n",
       "       [1.0001e+04, 5.0000e-01, 5.0000e-01, ..., 1.0000e-01, 5.0000e-01,\n",
       "        0.0000e+00],\n",
       "       [1.0003e+04, 1.0000e-01, 4.0000e-01, ..., 2.0000e-01, 4.0000e-01,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [9.9920e+03, 6.0000e-01, 2.0000e-01, ..., 1.0000e-01, 5.0000e-01,\n",
       "        0.0000e+00],\n",
       "       [9.9940e+03, 8.0000e-01, 7.0000e-01, ..., 3.0000e-01, 5.0000e-01,\n",
       "        3.0000e-01],\n",
       "       [9.9970e+03, 8.0000e-01, 2.0000e-01, ..., 1.0000e-01, 5.0000e-01,\n",
       "        0.0000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_part_1[:, 0] = test_X[:, 0]\n",
    "predictions_part_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1 & 2 FINISHED YAY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor = SGDRegressor(max_iter = 1000)\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.array(train_labels.loc[: , \"LABEL_RRate\":\"LABEL_Heartrate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_part_3 = np.zeros([12664,4])\n",
    "for i in range(4) :\n",
    "    regressor.fit(train_X, train_Y[:, i])\n",
    "    output = regressor.predict(test_X)\n",
    "    predictions_part_3[:, i] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.66736603,  83.67812794,  99.61592843,  75.09890837],\n",
       "       [ 18.05277743,  89.60932034,  94.65189006, 102.88920332],\n",
       "       [ 18.42808751,  79.13767478,  97.54655417,  89.90192853],\n",
       "       ...,\n",
       "       [ 18.95520558,  68.61558042,  97.08469495,  83.00656884],\n",
       "       [ 14.91720718,  85.45004304,  98.41375264,  97.11100004],\n",
       "       [ 18.09709982,  79.0646861 ,  98.42689539,  85.60912834]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_part_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yay = np.concatenate((predictions_part_1,predictions_part_3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12664, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(yay, columns = ['pid','LABEL_BaseExcess','LABEL_Fibrinogen','LABEL_AST','LABEL_Alkalinephos','LABEL_Bilirubin_total','LABEL_Lactate','LABEL_TroponinI','LABEL_SaO2','LABEL_Bilirubin_direct','LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate','LABEL_ABPm','LABEL_SpO2','LABEL_Heartrate'])\n",
    "\n",
    "df.to_csv('prediction.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
