Firstly we preprocessed train and test features: We created a new array where each element is one patient. For each patient we saved pid, age and a set of statistical features. Statistical features are mean, variance, maximal value, minimal value, median and trend, and we calculated those for each given feature. For mean, variance, maximum, minimum and median we used functions nanmean, nanvar, nanmax, nanmin and nanmedian respectively, because they deal with NaN values that appear in the data. Trend is calculated with polyfit of order 1. The slope of the fitted linear function describes the data trend. Zero means that the trend is constant. Positive number means increasing trend and negative decreasing. Higher number means faster increasing. Now we had an array of patients where each element (each patient) consisted of set of statistical features. At this point some values were still NaN. This would happen if for example the temperature for one patiend was never measured; then all statistical features related to temperature for this patient would be NaN. Those values were replaced with column means (Temperature mean of all patients for example). All statistical features were then standardized. 

We evaluated different methods with cross validation (function cross_val_score) and roc_auc (or R2 in task 3) scoring. We concluded that HistGradientBoosting is the best method for tasks 1 and 3, and RandomForestClassifier for task 2. In tasks 1 and 2 we used predict_proba function. Results were put in one array of labels and outputed in zipped cvs file.